{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Before proceeding, go to \"File\" and select option \"Save a copy in drive\" then and only then proceed. YOU WILL NOT BE ABLE TO SAVE CHANGES IN THIS NOTEBOOK"
      ],
      "metadata": {
        "id": "sGEVIbmAyudg"
      },
      "id": "sGEVIbmAyudg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing transformers library"
      ],
      "metadata": {
        "id": "IrKDQ1--xXic"
      },
      "id": "IrKDQ1--xXic"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmHT_1gxknLF",
        "outputId": "1f22e9f8-483c-4ba6-b74d-4961a8f58860"
      },
      "id": "EmHT_1gxknLF",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Libraries"
      ],
      "metadata": {
        "id": "_K_u5cj2xPm-"
      },
      "id": "_K_u5cj2xPm-"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from warnings import filterwarnings\n",
        "import torch\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "DUDQojnxSsuR"
      },
      "id": "DUDQojnxSsuR",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google T5 SLM"
      ],
      "metadata": {
        "id": "xjYZOjSlxZfz"
      },
      "id": "xjYZOjSlxZfz"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "input_text = \"translate English to German: How old are you?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k4DDtnNkqxU",
        "outputId": "78addfb5-1d02-4f5b-c37a-1490ddbea5ab"
      },
      "id": "0k4DDtnNkqxU",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> Wie old sind Sie?</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hypertuned SLM for Summarization task"
      ],
      "metadata": {
        "id": "-zi3xg2Xxd18"
      },
      "id": "-zi3xg2Xxd18"
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'tuner007/pegasus_summarizer'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def get_response(input_text):\n",
        "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=1024, return_tensors=\"pt\").to(torch_device)\n",
        "  gen_out = model.generate(**batch,max_length=128,num_beams=5, num_return_sequences=1, temperature=1.5)\n",
        "  output_text = tokenizer.batch_decode(gen_out, skip_special_tokens=True)\n",
        "  return output_text[0]"
      ],
      "metadata": {
        "id": "Ex_qvTbCk1ms"
      },
      "id": "Ex_qvTbCk1ms",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\"In the midst of the ever-evolving digital landscape, a particular technology has begun to stand out for its transformative potential in various industries: blockchain. This decentralized ledger technology, best known for underpinning cryptocurrencies like Bitcoin and Ethereum, has far-reaching implications beyond the financial sector. At its core, blockchain provides a secure and transparent way to record transactions and manage data across a network of computers, eliminating the need for a central authority. This feature not only enhances security and transparency but also opens up new avenues for innovation in fields such as healthcare, supply chain management, and intellectual property rights, among others.\n",
        "\n",
        "In healthcare, for example, blockchain can revolutionize how patient records are stored and shared, ensuring data integrity while maintaining privacy. By allowing patient data to be securely shared among authorized providers, blockchain technology can facilitate more accurate diagnoses, personalized treatments, and efficient care coordination. Similarly, in the supply chain sector, blockchain can provide a transparent and tamper-proof record of the movement of goods, from production to delivery. This can help in tackling issues like counterfeit goods, delays in shipment, and lack of accountability, ultimately leading to more efficient operations and consumer trust.\n",
        "\n",
        "Moreover, the creative industries stand to benefit significantly from blockchain through the protection of intellectual property rights. By creating immutable records of content creation and ownership, artists and creators can safeguard their works against piracy and unauthorized use, ensuring fair compensation. Furthermore, blockchain's ability to execute smart contracts automatically—contracts that self-execute when certain conditions are met—can streamline processes, reduce costs, and eliminate the need for intermediaries in various transactions.\n",
        "\n",
        "Despite its potential, the adoption of blockchain technology faces challenges, including regulatory hurdles, scalability issues, and the need for a more robust infrastructure. Nevertheless, as these challenges are gradually addressed, blockchain is poised to offer innovative solutions to longstanding problems across industries, heralding a new era of efficiency, security, and transparency.\"\"\""
      ],
      "metadata": {
        "id": "5CRuqO6qlM9_"
      },
      "id": "5CRuqO6qlM9_",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_response(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "nWaPRct-lPrF",
        "outputId": "f154d570-6d3a-4bd2-a230-d672b4037676"
      },
      "id": "nWaPRct-lPrF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The adoption of blockchain technology faces challenges, including regulatory hurdles, scalability issues and the need for a more robust infrastructure, but it is poised to offer innovative solutions to longstanding problems across industries, a report said. It added that blockchain can help in tackling issues like counterfeit goods, delays in shipment, and lack of accountability, ultimately leading to more efficient operations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "v0AtSEEazDop"
      },
      "id": "v0AtSEEazDop"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  Thank you for joining us Ramadan Nights at GDSC-FSA, hope to see you next soon!\n",
        "</div>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/2b/a7/17/2ba717ac010d3b9f8d26e9db4da291b8.jpg\" alt=\"X.com/akajammythakkar\" width=\"20\" height=\"20\">\n",
        "  <img src=\"https://w7.pngwing.com/pngs/521/488/png-transparent-logo-computer-icons-instagram-logo-miscellaneous-text-logo.png\" alt=\"instagram.com/akajammythakkar\" width=\"20\" height=\"20\">\n",
        "  <img src=\"https://w7.pngwing.com/pngs/490/260/png-transparent-email-email-thumbnail.png\" alt=\"akajammythakkar@gmail.com\" width=\"20\" height=\"20\">\n",
        "  <img src=\"https://w7.pngwing.com/pngs/940/589/png-transparent-linkedin-free-text-telephone-call-trademark-thumbnail.png\" alt=\"linkedin.com/in/akajammythakkar\" width=\"20\" height=\"20\">\n",
        "  <a href=\"https://imjt.dev\" target=\"_blank\">@akajammythakkar</a>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "i_SO_Y0syzog"
      },
      "id": "i_SO_Y0syzog"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqbCpp7zzR2k"
      },
      "id": "tqbCpp7zzR2k",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}